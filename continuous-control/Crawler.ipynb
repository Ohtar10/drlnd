{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program!  In this notebook, you will learn how to control an agent in a more challenging environment, where the goal is to train a creature with four arms to walk forward.  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Crawler.app\"`\n",
    "- **Windows** (x86): `\"path/to/Crawler_Windows_x86/Crawler.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Crawler_Windows_x86_64/Crawler.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Crawler_Linux/Crawler.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Crawler_Linux/Crawler.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Crawler.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='./Crawler_Linux/Crawler.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.36791125033050776\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, layer_units=[1024, 512, 256, 128]):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.layer_units = layer_units\n",
    "\n",
    "        for i in range(len(layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            units = layer_units[i]\n",
    "            if i == 0:\n",
    "                self.__setattr__(layer_name, nn.Linear(state_size, units))\n",
    "            else:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units, units))\n",
    "\n",
    "        prev_units = layer_units[-1]\n",
    "        self.__setattr__(f'fc{len(layer_units) + 1}', nn.Linear(prev_units, action_size))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)            \n",
    "            layer.weight.data.uniform_(*hidden_init(layer))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        layer.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)\n",
    "            if i == 0:\n",
    "                x = torch.relu(layer(state))\n",
    "            else:\n",
    "                x = torch.relu(layer(x))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        return torch.tanh(layer(x))\n",
    "        \n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, layer_units=[1024, 512, 256, 128]):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.layer_units = layer_units\n",
    "\n",
    "        for i in range(len(layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            units = layer_units[i]\n",
    "            if i == 0:\n",
    "                self.__setattr__(layer_name, nn.Linear(state_size, units))\n",
    "            elif i == 1:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units + action_size, units))            \n",
    "            else:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units, units))\n",
    "\n",
    "        prev_units = layer_units[-1]\n",
    "        self.__setattr__(f'fc{len(layer_units) + 1}', nn.Linear(prev_units, 1))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)            \n",
    "            layer.weight.data.uniform_(*hidden_init(layer))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        layer.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)\n",
    "            if i == 0:\n",
    "                xs = torch.relu(layer(state))\n",
    "                x = torch.cat((xs, action), dim=1)\n",
    "            else:\n",
    "                x = torch.relu(layer(x))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        return layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rlcode/per.git\n",
    "class SumTree:\n",
    "    write = 0 \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "        \n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "    \n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "        \n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        dataIdx = idx - self.capacity + 1\n",
    "\n",
    "        return (idx, self.tree[idx], self.data[dataIdx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size, seed, device, e: float = 0.01, a: float = 0.6, beta: float = 0.4, beta_increment_per_sampling = 1e-3):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.e = e\n",
    "        self.a = a\n",
    "        self.beta = beta\n",
    "        self.beta_increment_per_sampling = beta_increment_per_sampling\n",
    "\n",
    "        self.tree = SumTree(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        self.device = device\n",
    "\n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "    \n",
    "    def add(self, error, sample):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        state, action, reward, next_state, done = sample\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = []\n",
    "        idxs = []\n",
    "        segment = self.tree.total() / self.batch_size\n",
    "        priorities = []\n",
    "\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])\n",
    "\n",
    "        i = 0\n",
    "        while i < self.batch_size:\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = random.uniform(a, b)\n",
    "            idx, p, data = self.tree.get(s)\n",
    "            if not isinstance(data, tuple):\n",
    "                continue\n",
    "            priorities.append(p)\n",
    "            experiences.append(data)\n",
    "            idxs.append(idx)\n",
    "            i += 1\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones), idxs, is_weight\n",
    "\n",
    "    \n",
    "    def update(self, idx, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(idx, p)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return self.tree.n_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.1, scale=1.0, scale_decay=1.0):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.initial_scale = scale\n",
    "        self.scale = scale\n",
    "        self.scale_decay = scale_decay\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "        self.scale = self.initial_scale\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        # dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        scale = self.scale\n",
    "        self.scale *= self.scale_decay\n",
    "        return self.state * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        state_size: int, \n",
    "        action_size: int, \n",
    "        random_seed: int,\n",
    "        buffer_size: int=int(1e5),\n",
    "        batch_size: int=128,\n",
    "        gamma: float=0.99,\n",
    "        tau: float=1e-3,\n",
    "        lr_actor: float=1e-4,\n",
    "        lr_critic: float=1e-3,\n",
    "        weight_decay: float=0.0,\n",
    "        noise_scale: float=1.0,\n",
    "        noise_decay: float=1.0, \n",
    "        device: str=\"cpu\"\n",
    "        ):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=lr_actor)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=lr_critic, weight_decay=weight_decay)\n",
    "        \n",
    "        self.clone_weights(self.actor_target, self.actor_local) # ADDED\n",
    "        self.clone_weights(self.critic_target, self.critic_local) # ADDED\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed, scale=noise_scale, scale_decay=noise_decay)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(buffer_size, batch_size, random_seed, device)\n",
    "\n",
    "    def clone_weights(self, w1, w0): # ADDED\n",
    "        for p1, p0 in zip(w1.parameters(), w0.parameters()):\n",
    "            p1.data.copy_(p0.data)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        s = torch.from_numpy(state).float().to(self.device)\n",
    "        ns = torch.from_numpy(next_state).float().to(self.device)\n",
    "        r = torch.from_numpy(reward).float().to(self.device)\n",
    "        d = torch.from_numpy(done).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            oan = self.actor_local(ns)\n",
    "            oqtn = self.critic_local(ns, oan)\n",
    "            oqt = reward + (self.gamma * oqtn.cpu().numpy() * (1 - done))\n",
    "\n",
    "            an = self.actor_target(ns)\n",
    "            qtn = self.critic_target(ns, an)\n",
    "            qt = reward + (self.gamma * qtn.cpu().numpy() * (1 - done))\n",
    "\n",
    "        errors = np.abs(oqt - qt).squeeze()\n",
    "        for i, error in enumerate(errors):\n",
    "            self.memory.add(error, (state[i], action[i], reward[i], next_state[i], done[i]))\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            experiences, idxs, is_weights = self.memory.sample()\n",
    "            self.learn(experiences, idxs, is_weights)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(self.device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, idxs, is_weights):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # update experience priorities\n",
    "        errors = torch.abs(Q_expected - Q_targets).cpu().detach().numpy()\n",
    "        # print(f\"errors: {errors.shape}, idxs: {len(idxs)}\")\n",
    "        for i in range(self.batch_size):\n",
    "            idx = idxs[i]\n",
    "            self.memory.update(idx, errors[i])\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1) # ADDED\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, self.tau)\n",
    "        self.soft_update(self.actor_local, self.actor_target, self.tau)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "    def save(self, path :str) -> None:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        torch.save(self.actor_local.state_dict(), f'{path}/crawler-checkpoint_actor.pth')\n",
    "        torch.save(self.critic_local.state_dict(), f'{path}/crawler-checkpoint_critic.pth')\n",
    "        torch.save(self.actor_target.state_dict(), f'{path}/crawler-checkpoint_actor_target.pth')\n",
    "        torch.save(self.critic_target.state_dict(), f'{path}/crawler-checkpoint_critic_target.pth')\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        self.actor_local.load_state_dict(torch.load(f'{path}/crawler-checkpoint_actor.pth'))\n",
    "        self.actor_target.load_state_dict(torch.load(f'{path}/crawler-checkpoint_actor_target.pth'))\n",
    "        self.critic_local.load_state_dict(torch.load(f'{path}/crawler-checkpoint_critic.pth'))\n",
    "        self.critic_target.load_state_dict(torch.load(f'{path}/crawler-checkpoint_critic_target.pth'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def ddpg(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes=1000, \n",
    "    max_t=300,\n",
    "    save_dir=None,\n",
    "    ):\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = []\n",
    "    avg_scores = []\n",
    "    solved = False\n",
    "    with tqdm(total=n_episodes) as progress:\n",
    "        for i_episode in range(1, n_episodes+1):\n",
    "            env_info = env.reset(train_mode=True)[brain_name]\n",
    "            states = env_info.vector_observations\n",
    "            num_agents = len(env_info.agents)\n",
    "            score = np.zeros(num_agents)\n",
    "            agent.reset()\n",
    "            for t in range(max_t):\n",
    "                actions = agent.act(states)\n",
    "                env_info = env.step(actions)[brain_name]\n",
    "                next_states = env_info.vector_observations\n",
    "                rewards = env_info.rewards\n",
    "                rewards = np.expand_dims(np.asanyarray(rewards), axis=1)\n",
    "                dones = env_info.local_done\n",
    "                dones = np.expand_dims(np.asanyarray(dones), axis=1)\n",
    "                \n",
    "                agent.step(states, actions, rewards, next_states, dones)\n",
    "                states = next_states\n",
    "                score += np.squeeze(rewards)\n",
    "                if np.any(dones):\n",
    "                    break\n",
    "                \n",
    "            score = np.mean(score) \n",
    "            scores_window.append(score)\n",
    "            scores.append(score)\n",
    "            avg_score = np.mean(scores_window)\n",
    "            avg_scores.append(avg_score)\n",
    "            \n",
    "            progress.set_postfix({\"Avg. Score\": f\"{avg_score:.2f}\"})\n",
    "            progress.update()\n",
    "\n",
    "            if i_episode >=100 and np.mean(scores_window) >= 3000.0:\n",
    "                print(f\"Environment solved at {i_episode} episodes with Avg. score: {avg_score:.2f}\")\n",
    "                agent.save(save_dir)\n",
    "                solved = True\n",
    "                break\n",
    "            \n",
    "    return scores, avg_scores, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.07s/it, Avg. Score=1.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 940 ms, total: 1min 23s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "agent = Agent(\n",
    "    state_size, \n",
    "    action_size, \n",
    "    random_seed=123, \n",
    "    buffer_size=int(1e6),\n",
    "    batch_size=512,\n",
    "    lr_actor=1e-4,\n",
    "    lr_critic=1e-4,\n",
    "    gamma=0.99, \n",
    "    noise_scale=2.0,\n",
    "    noise_decay=9e-4,\n",
    "    device=device)\n",
    "\n",
    "save_dir = \"crawler-model\"\n",
    "progress_path = 'crawler-progress'\n",
    "continue_from_cp = False\n",
    "cp_sequence = 0\n",
    "\n",
    "if os.path.exists(save_dir) and os.path.isdir(save_dir) and len(os.listdir(save_dir)) > 0:\n",
    "    agent.load(save_dir)\n",
    "    continue_from_cp = True\n",
    "    cp_sequence = max([int(re.match(r'.+-(\\d+)\\.pkl$', d).group(1)) for d in os.listdir(progress_path) if re.match(r'.+-(\\d+)\\.pkl$', d) is not None])\n",
    "    cp_sequence += 1\n",
    "\n",
    "# Run experiment\n",
    "scores, avg_scores, solved = ddpg(agent, env, n_episodes=1000, max_t=2000)\n",
    "if not solved:\n",
    "    agent.save(save_dir)\n",
    "\n",
    "os.makedirs(progress_path, exist_ok=True)\n",
    "with open(f'{progress_path}/scores-{cp_sequence}.pkl', mode='wb') as f:\n",
    "    obj = {\n",
    "        'scores': scores,\n",
    "        'avg_scores': avg_scores\n",
    "    }\n",
    "    pickle.dump(obj, f)\n",
    "\n",
    "if continue_from_cp:\n",
    "    scores = []\n",
    "    avg_scores = []\n",
    "    for i in range(cp_sequence + 1):\n",
    "        with open(f'{progress_path}/scores-{i}.pkl', mode='rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "            scores.extend(obj['scores'])\n",
    "            avg_scores.extend(obj['avg_scores'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_scores(scores, avg_scores):\n",
    "    \"\"\"plot scores.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    x = np.arange(len(scores))\n",
    "    y = scores\n",
    "    \n",
    "    plt.plot(x, y, label=\"scores\")\n",
    "    plt.plot(x, avg_scores, label=\"avg. scores\")\n",
    "    \n",
    "    plt.ylabel(\"Score\", fontsize=14)\n",
    "    plt.xlabel(\"Episode #\", fontsize=14)\n",
    "    plt.title(\"Agent progress over episodes\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores, avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent, env, num_agents, n_episodes=5, max_t=1000):\n",
    "    \"\"\"play.\n",
    "    \n",
    "    Uses the provided agent to play the game.\n",
    "    There is no training in this code, only playing.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    with tqdm(total=n_episodes) as progress:\n",
    "        for i_episode in range(1, n_episodes + 1):\n",
    "            env_info = env.reset(train_mode=False)[brain_name]\n",
    "            state = env_info.vector_observations\n",
    "            score = np.zeros(num_agents)\n",
    "            for _ in range(max_t):\n",
    "                # Let's not add noise here as we want to exploit the learned behaviour\n",
    "                action = agent.act(state, add_noise=False)\n",
    "                env_info = env.step(action)[brain_name]\n",
    "                next_state, reward, done = env_info.vector_observations, env_info.rewards, env_info.local_done\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if np.any(done):\n",
    "                    break\n",
    "            score = np.mean(score)\n",
    "            scores.append(score)\n",
    "            progress.set_postfix({\"Avg. Score\": f\"{np.mean(scores):.2f}\"})\n",
    "            progress.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.28s/it, Avg. Score=0.29]\n"
     ]
    }
   ],
   "source": [
    "play(agent, env, num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4678b387a0ef394384f4eb3455936a24d8793c524f8866d5fc54ef306707d4b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('drlnd-cont-control': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
