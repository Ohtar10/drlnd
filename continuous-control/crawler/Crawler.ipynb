{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program!  In this notebook, you will learn how to control an agent in a more challenging environment, where the goal is to train a creature with four arms to walk forward.  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.registry import default_registry\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Crawler.app\"`\n",
    "- **Windows** (x86): `\"path/to/Crawler_Windows_x86/Crawler.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Crawler_Windows_x86_64/Crawler.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Crawler_Linux/Crawler.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Crawler_Linux/Crawler.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Crawler_Linux_NoVis/Crawler.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Crawler.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = UnityEnvironment(file_name='./Crawler_Linux/Crawler.x86_64')\n",
    "env = UnityEnvironment(file_name='/home/luis-ferro/test/unity-mlagents/Playground/Builds/Crawler.x86_64')\n",
    "# env = default_registry['CrawlerStaticTarget'].make()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BehaviorSpec(observation_specs=[ObservationSpec(shape=(126,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='PhysicsBodySensor:Body'), ObservationSpec(shape=(32,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size32')], action_spec=ActionSpec(continuous_size=20, discrete_branches=()))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_name = list(env.behavior_specs)[0]\n",
    "behavior_spec = env.behavior_specs[behavior_name]\n",
    "behavior_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 9\n",
      "Size of each action: 20\n",
      "Number of observations: 2\n",
      "Observation space: (126,)\n",
      "There are 9 agents. Each observes a state with length: (126,)\n",
      "The state if the first agent looks like: \n",
      " DecisionStep(obs=[array([-1.5258789e-05, -7.2157383e-03,  1.5258789e-05, -6.8298455e-06,\n",
      "       -3.4842911e-01, -2.0962533e-04, -9.3733513e-01,  6.6253662e-02,\n",
      "       -1.3015985e-01, -8.9758301e-01,  6.8731236e-01,  2.6850380e-02,\n",
      "        2.5180817e-02, -7.2542858e-01,  1.4569092e-01, -1.7535329e-01,\n",
      "       -1.9746704e+00,  7.3637313e-01,  2.5047736e-02,  2.6944000e-02,\n",
      "       -6.7557472e-01, -8.9758301e-01, -1.3001561e-01, -6.6207886e-02,\n",
      "        5.0243717e-01, -4.9525428e-01, -4.6685135e-01, -5.3322589e-01,\n",
      "       -1.9746704e+00, -1.7414832e-01, -1.4564514e-01,  5.3953069e-01,\n",
      "       -4.6035105e-01, -5.0130951e-01, -4.9565330e-01, -6.6192627e-02,\n",
      "       -1.3012457e-01,  8.9759827e-01,  2.5262259e-02, -7.2547233e-01,\n",
      "       -6.8726772e-01, -2.6736440e-02, -1.4559937e-01, -1.7521238e-01,\n",
      "        1.9746857e+00,  2.7098311e-02, -6.7561036e-01, -7.3634052e-01,\n",
      "       -2.4879264e-02,  8.9761353e-01, -1.2980938e-01,  6.6223145e-02,\n",
      "        4.6801832e-01,  5.3204399e-01,  5.0368911e-01, -4.9415109e-01,\n",
      "        1.9747162e+00, -1.7436552e-01,  1.4566040e-01,  5.0146472e-01,\n",
      "        4.9549124e-01,  5.3968042e-01, -4.6018112e-01, -1.9902604e-04,\n",
      "       -4.9914795e-01, -2.2171598e-05,  9.7393955e-04,  1.5174588e+00,\n",
      "       -8.2537258e-04,  1.8041601e-03, -2.1374981e+00, -8.7486114e-04,\n",
      "       -1.3556617e-03,  1.5281862e+00, -5.9591758e-04, -1.4158917e-03,\n",
      "       -2.0983224e+00,  1.9893446e-04, -4.6450633e-04,  1.5170414e+00,\n",
      "        9.0206810e-04,  2.2920968e-03, -2.1317220e+00,  1.2228710e-03,\n",
      "        9.3532697e-04,  1.5226264e+00,  5.2389811e-04,  1.1219528e-03,\n",
      "       -2.0927689e+00, -1.1286172e-04, -6.8298455e-06, -3.4842911e-01,\n",
      "       -2.0962533e-04, -9.3733513e-01, -6.3547891e-01, -2.7778438e-01,\n",
      "       -2.6323441e-01,  6.7060435e-01, -6.9947988e-02, -5.4439181e-05,\n",
      "        2.1854446e-05,  9.9755067e-01, -6.3351649e-01,  2.7853632e-01,\n",
      "        2.6241729e-01,  6.7246687e-01, -7.2017305e-02,  7.7255260e-07,\n",
      "        7.4092727e-06,  9.9740338e-01, -2.6299143e-01,  6.7070496e-01,\n",
      "        6.3538754e-01,  2.7798060e-01, -6.9965474e-02,  3.6368438e-05,\n",
      "       -3.2216385e-06,  9.9754947e-01, -2.6330498e-01, -6.7078555e-01,\n",
      "       -6.3529670e-01,  2.7769676e-01, -6.9986358e-02, -1.2901427e-05,\n",
      "        6.8696995e-06,  9.9754798e-01], dtype=float32), array([ 1.04837523e+01,  4.10265580e-04, -3.19349647e-01,  4.62874596e-05,\n",
      "        0.00000000e+00,  0.00000000e+00,  1.04789333e+01, -1.37856505e-05,\n",
      "       -3.48429084e-01,  6.97433352e-05,  9.37335193e-01, -1.90734863e-06,\n",
      "       -1.52614832e-01,  3.04292259e+01,  2.14878470e-01,  0.00000000e+00,\n",
      "        0.00000000e+00,  5.00000000e-01,  0.00000000e+00,  5.00000000e-01,\n",
      "        0.00000000e+00,  5.00000000e-01,  0.00000000e+00,  5.00000000e-01,\n",
      "        0.00000000e+00,  5.00000000e-01,  0.00000000e+00,  5.00000000e-01,\n",
      "        0.00000000e+00,  5.00000000e-01,  0.00000000e+00,  5.00000000e-01],\n",
      "      dtype=float32)], reward=0.0, agent_id=0, action_mask=None, group_id=0, group_reward=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Reset the Environment\n",
    "env.reset()\n",
    "behavior_spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "# Number of agents\n",
    "decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "num_agents = len(decision_steps)\n",
    "print(f\"Number of agents: {num_agents}\")\n",
    "\n",
    "# Size of each action\n",
    "action_size = behavior_spec.action_spec.continuous_size\n",
    "print(f\"Size of each action: {action_size}\")\n",
    "\n",
    "# Examine the state space\n",
    "obs_specs = behavior_spec.observation_specs\n",
    "num_obs = len(obs_specs)\n",
    "state_size = obs_specs[0].shape\n",
    "print(f\"Number of observations: {num_obs}\")\n",
    "print(f\"Observation space: {state_size}\")\n",
    "print(f\"There are {num_agents} agents. Each observes a state with length: {state_size}\")\n",
    "print(\"The state if the first agent looks like: \\n\", decision_steps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: -0.10919175567404535\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "behavior_name = list(env.behavior_specs)[0]\n",
    "behavior_spec = env.behavior_specs[behavior_name]\n",
    "ds, ts = env.get_steps(behavior_name)\n",
    "states = ds.obs[0]\n",
    "scores = np.zeros(num_agents)\n",
    "dones = np.zeros(num_agents)\n",
    "while True:\n",
    "    # Select random action for each agent\n",
    "    action = behavior_spec.action_spec.random_action(num_agents)\n",
    "    # Set the actions\n",
    "    env.set_actions(behavior_name, action)\n",
    "    # Move the simulation one step ahead\n",
    "    env.step()\n",
    "    # Get the s,a,r,ns tuple\n",
    "    ds, ts = env.get_steps(behavior_name)\n",
    "    if len(ts) > 0:\n",
    "        for agent_id in ts:\n",
    "            scores[agent_id] += ts[agent_id].reward\n",
    "            dones[agent_id] = 1\n",
    "        break\n",
    "    next_states = ds.obs[0]\n",
    "    scores += ds.reward\n",
    "    states = next_states\n",
    "\n",
    "print(f\"Total score (averaged over agents) this episode: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, layer_units=[512, 256, 128]):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.layer_units = layer_units\n",
    "\n",
    "        for i in range(len(layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            units = layer_units[i]\n",
    "            if i == 0:\n",
    "                self.__setattr__(layer_name, nn.Linear(state_size, units))\n",
    "            else:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units, units))\n",
    "\n",
    "        prev_units = layer_units[-1]\n",
    "        self.__setattr__(f'fc{len(layer_units) + 1}', nn.Linear(prev_units, action_size))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)            \n",
    "            layer.weight.data.uniform_(*hidden_init(layer))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        layer.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)\n",
    "            if i == 0:\n",
    "                x = torch.relu(layer(state))\n",
    "            else:\n",
    "                x = torch.relu(layer(x))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        return torch.tanh(layer(x))\n",
    "        \n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, layer_units=[512, 256, 128]):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.layer_units = layer_units\n",
    "\n",
    "        for i in range(len(layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            units = layer_units[i]\n",
    "            if i == 0:\n",
    "                self.__setattr__(layer_name, nn.Linear(state_size, units))\n",
    "            elif i == 1:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units + action_size, units))            \n",
    "            else:\n",
    "                prev_units = layer_units[i-1]\n",
    "                self.__setattr__(layer_name, nn.Linear(prev_units, units))\n",
    "\n",
    "        prev_units = layer_units[-1]\n",
    "        self.__setattr__(f'fc{len(layer_units) + 1}', nn.Linear(prev_units, 1))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)            \n",
    "            layer.weight.data.uniform_(*hidden_init(layer))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        layer.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        for i in range(len(self.layer_units)):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            layer = self.__getattr__(layer_name)\n",
    "            if i == 0:\n",
    "                xs = torch.relu(layer(state))\n",
    "                x = torch.cat((xs, action), dim=1)\n",
    "            else:\n",
    "                x = torch.relu(layer(x))\n",
    "\n",
    "        last_layer_name = f'fc{len(self.layer_units) + 1}'\n",
    "        layer = self.__getattr__(last_layer_name)\n",
    "        return layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rlcode/per.git\n",
    "class SumTree:\n",
    "    write = 0 \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "        \n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "    \n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "        \n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        dataIdx = idx - self.capacity + 1\n",
    "\n",
    "        return (idx, self.tree[idx], self.data[dataIdx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size, seed, device, e: float = 0.01, a: float = 0.6, beta: float = 0.4, beta_increment_per_sampling = 1e-3):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.e = e\n",
    "        self.a = a\n",
    "        self.beta = beta\n",
    "        self.beta_increment_per_sampling = beta_increment_per_sampling\n",
    "\n",
    "        self.tree = SumTree(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        self.device = device\n",
    "\n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "    \n",
    "    def add(self, error, sample):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        state, action, reward, next_state, done = sample\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = []\n",
    "        idxs = []\n",
    "        segment = self.tree.total() / self.batch_size\n",
    "        priorities = []\n",
    "\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])\n",
    "\n",
    "        i = 0\n",
    "        while i < self.batch_size:\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = random.uniform(a, b)\n",
    "            idx, p, data = self.tree.get(s)\n",
    "            if not isinstance(data, tuple):\n",
    "                continue\n",
    "            priorities.append(p)\n",
    "            experiences.append(data)\n",
    "            idxs.append(idx)\n",
    "            i += 1\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones), idxs, is_weight\n",
    "\n",
    "    \n",
    "    def update(self, idx, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(idx, p)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return self.tree.n_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.1, scale=1.0, scale_decay=1.0):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.initial_scale = scale\n",
    "        self.scale = scale\n",
    "        self.scale_decay = scale_decay\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "        self.scale = self.initial_scale\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        # dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        scale = self.scale\n",
    "        self.scale *= self.scale_decay\n",
    "        return self.state * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        state_size: int, \n",
    "        action_size: int, \n",
    "        random_seed: int,\n",
    "        buffer_size: int=int(1e5),\n",
    "        batch_size: int=128,\n",
    "        gamma: float=0.99,\n",
    "        tau: float=1e-3,\n",
    "        lr_actor: float=1e-4,\n",
    "        lr_critic: float=1e-3,\n",
    "        weight_decay: float=0.0,\n",
    "        noise_scale: float=1.0,\n",
    "        noise_decay: float=1.0, \n",
    "        device: str=\"cpu\"\n",
    "        ):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=lr_actor)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=lr_critic, weight_decay=weight_decay)\n",
    "        \n",
    "        self.clone_weights(self.actor_target, self.actor_local) # ADDED\n",
    "        self.clone_weights(self.critic_target, self.critic_local) # ADDED\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed, scale=noise_scale, scale_decay=noise_decay)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(buffer_size, batch_size, random_seed, device)\n",
    "\n",
    "    def clone_weights(self, w1, w0): # ADDED\n",
    "        for p1, p0 in zip(w1.parameters(), w0.parameters()):\n",
    "            p1.data.copy_(p0.data)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        s = torch.from_numpy(state).float().to(self.device)\n",
    "        ns = torch.from_numpy(next_state).float().to(self.device)\n",
    "        r = torch.from_numpy(reward).float().to(self.device)\n",
    "        d = torch.from_numpy(done).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            oan = self.actor_local(ns)\n",
    "            oqtn = self.critic_local(ns, oan)\n",
    "            oqt = reward + (self.gamma * oqtn.cpu().numpy() * (1 - done))\n",
    "\n",
    "            an = self.actor_target(ns)\n",
    "            qtn = self.critic_target(ns, an)\n",
    "            qt = reward + (self.gamma * qtn.cpu().numpy() * (1 - done))\n",
    "\n",
    "        errors = np.abs(oqt - qt)\n",
    "        if len(errors) > 1:\n",
    "            errors = errors.squeeze()\n",
    "\n",
    "        for i, error in enumerate(errors):\n",
    "            self.memory.add(error, (state[i], action[i], reward[i], next_state[i], done[i]))\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            experiences, idxs, is_weights = self.memory.sample()\n",
    "            self.learn(experiences, idxs, is_weights)\n",
    "\n",
    "    def act(self, state, add_noise=True, clip=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(self.device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        if clip:\n",
    "            return np.clip(action, -1, 1)\n",
    "        else:\n",
    "            return action\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, idxs, is_weights):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # update experience priorities\n",
    "        errors = torch.abs(Q_expected - Q_targets).cpu().detach().numpy()\n",
    "        # print(f\"errors: {errors.shape}, idxs: {len(idxs)}\")\n",
    "        for i in range(self.batch_size):\n",
    "            idx = idxs[i]\n",
    "            self.memory.update(idx, errors[i])\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), 1) # ADDED\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, self.tau)\n",
    "        self.soft_update(self.actor_local, self.actor_target, self.tau)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "    def save(self, path :str) -> None:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        torch.save(self.actor_local.state_dict(), f'{path}/crawler-checkpoint_actor.pth')\n",
    "        torch.save(self.critic_local.state_dict(), f'{path}/crawler-checkpoint_critic.pth')\n",
    "        torch.save(self.actor_target.state_dict(), f'{path}/crawler-checkpoint_actor_target.pth')\n",
    "        torch.save(self.critic_target.state_dict(), f'{path}/crawler-checkpoint_critic_target.pth')\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        self.actor_local.load_state_dict(torch.load(f'{path}/crawler-checkpoint_actor.pth'))\n",
    "        self.actor_target.load_state_dict(torch.load(f'{path}/crawler-checkpoint_actor_target.pth'))\n",
    "        self.critic_local.load_state_dict(torch.load(f'{path}/crawler-checkpoint_critic.pth'))\n",
    "        self.critic_target.load_state_dict(torch.load(f'{path}/crawler-checkpoint_critic_target.pth'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from mlagents_envs.environment import ActionTuple\n",
    "\n",
    "def ddpg(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes=1000, \n",
    "    max_t=300,\n",
    "    save_dir=None,\n",
    "    ):\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = []\n",
    "    avg_scores = []\n",
    "    solved = False\n",
    "    with tqdm(total=n_episodes) as progress:\n",
    "        for i_episode in range(1, n_episodes+1):\n",
    "            # env_info = env.reset(train_mode=True)[brain_name]\n",
    "            env.reset()\n",
    "            ds, _ = env.get_steps(behavior_name)\n",
    "            states = ds.obs[0]\n",
    "            num_agents = len(ds)\n",
    "            score = np.zeros((num_agents, 1))\n",
    "            agent.reset()\n",
    "            for t in range(max_t):\n",
    "                actions = agent.act(states, clip=False)\n",
    "                action_tuple = ActionTuple(continuous=actions)\n",
    "                \n",
    "                env.set_actions(behavior_name, action_tuple)\n",
    "                # Move the simulation one step ahead\n",
    "                env.step()\n",
    "                # Get the s,a,r,ns tuple\n",
    "                ds, ts = env.get_steps(behavior_name)\n",
    "                dones = np.zeros((num_agents, 1))\n",
    "                \n",
    "                if len(ds) > 0:\n",
    "                    next_states = ds.obs[0]\n",
    "                    rewards = ds.reward\n",
    "                    rewards = np.expand_dims(np.asanyarray(rewards), axis=1)\n",
    "                    \n",
    "                    agent.step(states, actions, rewards, next_states, dones)\n",
    "                    states = next_states\n",
    "                    score += rewards\n",
    "\n",
    "                # Break if there are any terminal states\n",
    "                if len(ts) > 0:\n",
    "                    agent_ids = [ai for ai in ts]\n",
    "                    states = states[agent_ids, :]\n",
    "                    next_states = ts.obs[0]\n",
    "                    rewards = ts.reward\n",
    "                    rewards = np.expand_dims(np.asanyarray(rewards), axis=1)\n",
    "                    dones = np.ones((len(ts), 1))\n",
    "                    agent.step(states, actions, rewards, next_states, dones)\n",
    "                    for ai in agent_ids:\n",
    "                        score[ai] += ts[ai].reward\n",
    "                    break\n",
    "                \n",
    "            score = np.mean(score) \n",
    "            scores_window.append(score)\n",
    "            scores.append(score)\n",
    "            avg_score = np.mean(scores_window)\n",
    "            avg_scores.append(avg_score)\n",
    "            \n",
    "            progress.set_postfix({\"Avg. Score\": f\"{avg_score:.2f}\"})\n",
    "            progress.update()\n",
    "\n",
    "            if i_episode >=100 and np.mean(scores_window) >= 3000.0:\n",
    "                print(f\"Environment solved at {i_episode} episodes with Avg. score: {avg_score:.2f}\")\n",
    "                agent.save(save_dir)\n",
    "                solved = True\n",
    "                break\n",
    "            \n",
    "    return scores, avg_scores, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:17:42<00:00,  2.33s/it, Avg. Score=1.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 14min 49s, sys: 17.8 s, total: 1h 15min 7s\n",
      "Wall time: 1h 17min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_episodes = 2000\n",
    "# device = \"cpu\"\n",
    "# agent = Agent(\n",
    "#     state_size[0], \n",
    "#     action_size, \n",
    "#     random_seed=123, \n",
    "#     buffer_size=int(1e8),\n",
    "#     batch_size=1024,\n",
    "#     lr_actor=1e-4,\n",
    "#     lr_critic=1e-3,\n",
    "#     gamma=0.995, \n",
    "#     noise_scale=2.5,\n",
    "#     noise_decay=9e-3,\n",
    "#     device=device)\n",
    "\n",
    "save_dir = \"crawler-model\"\n",
    "progress_path = 'crawler-progress'\n",
    "continue_from_cp = False\n",
    "cp_sequence = 0\n",
    "\n",
    "if os.path.exists(save_dir) and os.path.isdir(save_dir) and len(os.listdir(save_dir)) > 0:\n",
    "    agent.load(save_dir)\n",
    "    continue_from_cp = True\n",
    "    cp_sequence = max([int(re.match(r'.+-(\\d+)\\.pkl$', d).group(1)) for d in os.listdir(progress_path) if re.match(r'.+-(\\d+)\\.pkl$', d) is not None])\n",
    "    cp_sequence += 1\n",
    "\n",
    "# Run experiment\n",
    "scores, avg_scores, solved = ddpg(agent, env, n_episodes=n_episodes, max_t=10000)\n",
    "if not solved:\n",
    "    agent.save(save_dir)\n",
    "\n",
    "os.makedirs(progress_path, exist_ok=True)\n",
    "with open(f'{progress_path}/scores-{cp_sequence}.pkl', mode='wb') as f:\n",
    "    obj = {\n",
    "        'scores': scores,\n",
    "        'avg_scores': avg_scores\n",
    "    }\n",
    "    pickle.dump(obj, f)\n",
    "\n",
    "if continue_from_cp:\n",
    "    scores = []\n",
    "    avg_scores = []\n",
    "    for i in range(cp_sequence + 1):\n",
    "        with open(f'{progress_path}/scores-{i}.pkl', mode='rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "            scores.extend(obj['scores'])\n",
    "            avg_scores.extend(obj['avg_scores'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_scores(scores, avg_scores):\n",
    "    \"\"\"plot scores.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    x = np.arange(len(scores))\n",
    "    y = scores\n",
    "    \n",
    "    plt.plot(x, y, label=\"scores\")\n",
    "    plt.plot(x, avg_scores, label=\"avg. scores\")\n",
    "    \n",
    "    plt.ylabel(\"Score\", fontsize=14)\n",
    "    plt.xlabel(\"Episode #\", fontsize=14)\n",
    "    plt.title(\"Agent progress over episodes\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores, avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent, env, num_agents, n_episodes=5, max_t=1000):\n",
    "    \"\"\"play.\n",
    "    \n",
    "    Uses the provided agent to play the game.\n",
    "    There is no training in this code, only playing.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    with tqdm(total=n_episodes) as progress:\n",
    "        for _ in range(1, n_episodes + 1):\n",
    "            env.reset()\n",
    "            ds, _ = env.get_steps(behavior_name)\n",
    "            states = ds.obs[0]\n",
    "            num_agents = len(ds)\n",
    "            score = np.zeros((num_agents, 1))\n",
    "            agent.reset()\n",
    "            for _ in range(max_t):\n",
    "                actions = agent.act(states, clip=False)\n",
    "                action_tuple = ActionTuple(continuous=actions)\n",
    "                \n",
    "                env.set_actions(behavior_name, action_tuple)\n",
    "                # Move the simulation one step ahead\n",
    "                env.step()\n",
    "                # Get the s,a,r,ns tuple\n",
    "                ds, ts = env.get_steps(behavior_name)\n",
    "                \n",
    "                if len(ds) > 0:\n",
    "                    next_states = ds.obs[0]\n",
    "                    rewards = ds.reward\n",
    "                    rewards = np.expand_dims(np.asanyarray(rewards), axis=1)\n",
    "                    states = next_states\n",
    "                    score += rewards\n",
    "\n",
    "                # Break if there are any terminal states\n",
    "                if len(ts) > 0:\n",
    "                    agent_ids = [ai for ai in ts]\n",
    "                    states = states[agent_ids, :]\n",
    "                    next_states = ts.obs[0]\n",
    "                    for ai in agent_ids:\n",
    "                        score[ai] += ts[ai].reward\n",
    "                    break\n",
    "\n",
    "            score = np.mean(score)\n",
    "            scores.append(score)\n",
    "            progress.set_postfix({\"Avg. Score\": f\"{np.mean(scores):.2f}\"})\n",
    "            progress.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:08<00:00,  1.47it/s, Avg. Score=1.12]\n"
     ]
    }
   ],
   "source": [
    "play(agent, env, num_agents, n_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42666fd1b51428b2663dd79f5b665a8a5032ed98112cbcf125b1b69c1a75acba"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('drlnd-cont-control-2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
